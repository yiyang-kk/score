{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow contains set of methods (functions) that are necessary to develop and fine-tune gradient boosting model.\n",
    "\n",
    "Note: lgbm and shap packages has to be installed in computer.  \n",
    "--    pip install lightgbm  \n",
    "--    pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import operator\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import scoring\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.close_figures=True\n",
    "from IPython.display import display, Markdown\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 15\n",
    "\n",
    "scoring.check_version('0.7.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please adjust your path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='demo_data/kaggle_train_data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import db\n",
    "data = db.read_csv(data_path, compression='zip',sep = ',', decimal = '.',\n",
    "                   optimize_types=True, encoding = 'utf-8', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictors for default dataset are all columns, except of target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred=list(data)\n",
    "cols_pred.remove('TARGET')\n",
    "col_target='TARGET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to train/ test/ valid parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.data_manipulation import data_sample_time_split\n",
    "\n",
    "data['data_type'] = data_sample_time_split(data, \n",
    "                           time_column = '',\n",
    "                           splitting_points = [],\n",
    "                           sample_sizes = [[ 0.4 , 0.3, 0.3]],\n",
    "                           sample_names = [['train','valid','test'],[],],\n",
    "                           stratify_by_columns = [col_target],\n",
    "                           random_seed = 1234)\n",
    "\n",
    "train_mask = (data['data_type'] == 'train')\n",
    "valid_mask = (data['data_type'] == 'valid')\n",
    "test_mask = (data['data_type'] == 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting predictors to numerical x categorical parts.\n",
    "\n",
    "NOTE: Categorical predictors have to be as type 'category' , not 'object' !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.data_manipulation import split_predictors_bytype\n",
    "\n",
    "cols_pred, cols_pred_num, cols_pred_cat = split_predictors_bytype(data,\n",
    "                                                                  pred_list=cols_pred,\n",
    "                                                                  non_pred_list= [],\n",
    "                                                                  optimize_types=True,\n",
    "                                                                  convert_bool2int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting default parameters of lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'learning_rate':0.05,\n",
    "        'num_leaves':100,\n",
    "        'colsample_bytree':0.75,\n",
    "        'subsample':0.75,\n",
    "        'subsample_freq':1,\n",
    "        'max_depth':3,\n",
    "        'nthreads':3,\n",
    "        'verbose':1,\n",
    "        'metric':'auc',\n",
    "        'objective':'binary',\n",
    "        'early_stopping_rounds':100,\n",
    "        'num_boost_round':100000,\n",
    "        'seed':1234}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiation of lgbm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "#from importlib import reload\n",
    "from scoring import lgbm \n",
    "#lgbm=reload(lgbm)\n",
    "\n",
    "model_lgb = lgbm.LGBM_model(cols_pred, params, use_CV=False, CV_folds=3, CV_seed=9876)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit standard or cross-validated model\n",
    "output: List of lgbm boosters (models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=model_lgb.fit_model(data[train_mask], data[valid_mask], data[train_mask][col_target], data[valid_mask][col_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict to unseen dataset\n",
    "\n",
    "In case of CV is chosen, then the predictions are average predictions from each of CV models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = model_lgb.predict(model1, data[test_mask])\n",
    "print(2 * roc_auc_score(data[test_mask][col_target], predictions) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gain or weight variable importances\n",
    "\n",
    "Output: DataFrame with features and chosen importance\n",
    "\n",
    "In case of CV is chosen, then the variable importance is computed as the average variable importance from each CV models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp=model_lgb.plot_imp(model1, 'importance_gain', ret=True, show= True, n_predictors=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing shap values for given dataset\n",
    "\n",
    "Theoretical background for shap values can be found here https://christophm.github.io/interpretable-ml-book/shapley.html\n",
    "\n",
    "Output: DataFrame with features and its mean absolute shap values that coresponds with second chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_shap = model_lgb.print_shap_values(cols_pred_num, cols_pred_cat, data[train_mask], data[valid_mask], data[train_mask][col_target], data[valid_mask][col_target],data[test_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap interaction matrix\n",
    "\n",
    "Prints shap interaction matrix, based on https://christophm.github.io/interpretable-ml-book/shap.html#shap-interaction-value.\n",
    "It prints sum of absolute interactions values throught all observations.\n",
    "Diagonal values are manually set to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.print_shap_interaction_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap dependence plot\n",
    "Note: If y (second feature) is not specified, it is found automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.shap_dependence_plot(x='AMT_GOODS_PRICE',y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.shap_dependence_plot(x='AMT_GOODS_PRICE',y='AMT_ANNUITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap force plot for one observation\n",
    "If you are cuious why was given decision to particular observation.  \n",
    "Note: values in upper chart are in logloss, values in lower chart are in probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.shap_one_row(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters tunning \n",
    "Is based on maximalization of 3-fold cross-validation AUC.  \n",
    "Output is a dictionary of optimalized hyperparameters that could be paste into params before method iniciations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model_lgb.param_hyperopt(data[train_mask], data[valid_mask], data[train_mask][col_target], data[valid_mask][col_target], n_iter = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marginal contribution\n",
    "All features are one by one removed from model training and performance on the test data is computed.  \n",
    "Output is dataframe with 4 columns - feature, gini with feature, gini without feature and difference of gini with feature and gini without feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = model_lgb.marginal_contribution(data[train_mask], data[valid_mask], data[train_mask][col_target], data[valid_mask][col_target], data[test_mask], data[test_mask][col_target])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
