{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow is supposed to use data transformed by the initial PSW chapters, i.e.\n",
    "1. Import original dataset and create all important columns there (base, weight, month etc.)\n",
    "2. Data split\n",
    "3. Creation of date difference variables\n",
    "4. OPTIONALLY: creation of interactions and other derived features (gradient boosting is covering interaction between variables naturally, so it is not always necessary to create them manually)\n",
    "5. Export the transformed dataset and metadata about the important columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Note: lgbm and shap packages has to be installed in computer.  \n",
    "```\n",
    "pip install lightgbm\n",
    "pip install shap\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import operator\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import gc\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import scoring\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.close_figures=True\n",
    "from IPython.display import display, Markdown\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 15\n",
    "\n",
    "scoring.check_version('0.8.2', list_versions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = json.load(open(\"metadata.json\", \"r\", encoding=\"utf8\"))\n",
    "\n",
    "col_time = metadata[\"col_time\"]\n",
    "col_month = metadata[\"col_month\"]\n",
    "col_day = metadata[\"col_day\"]\n",
    "col_target = metadata[\"col_target\"]\n",
    "col_base = metadata[\"col_base\"]\n",
    "col_weight = metadata[\"col_weight\"]\n",
    "col_reject = metadata[\"col_reject\"]\n",
    "col_datatype = metadata[\"col_datatype\"]\n",
    "col_id = metadata[\"col_id\"]\n",
    "cols_pred_num = metadata[\"cols_pred_num\"]\n",
    "cols_pred_cat = metadata[\"cols_pred_cat\"]\n",
    "cols_pred = cols_pred_num + cols_pred_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import db\n",
    "data = db.read_csv('data_prepared.csv', index_col=col_id)\n",
    "data[col_id] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (data[col_datatype] == 'train') & (data[col_base] == 1)\n",
    "valid_mask = (data[col_datatype] == 'valid') & (data[col_base] == 1)\n",
    "test_mask = (data[col_datatype] == 'test') & (data[col_base] == 1)\n",
    "oot_mask = (data[col_datatype] == 'oot') & (data[col_base] == 1)\n",
    "hoot_mask = (data[col_datatype] == 'hoot') & (data[col_base] == 1)\n",
    "observable_mask = (data[col_base] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structures for documentation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.close_figures=True\n",
    "from IPython.display import display, Markdown, HTML\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 15\n",
    "output_folder = 'documentation_lgbm'\n",
    "\n",
    "if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "if not os.path.exists(output_folder+'/shap'): os.makedirs(output_folder+'/shap')\n",
    "if not os.path.exists(output_folder+'/pdp'): os.makedirs(output_folder+'/pdp')\n",
    "if not os.path.exists(output_folder+'/ice'): os.makedirs(output_folder+'/ice')\n",
    "if not os.path.exists(output_folder+'/psi'): os.makedirs(output_folder+'/psi')\n",
    "if not os.path.exists(output_folder+'/stability'): os.makedirs(output_folder+'/stability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import doctools\n",
    "\n",
    "documentation = doctools.ProjectParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation.targets = [(col_target, col_base)]\n",
    "documentation.time_variable = col_month\n",
    "documentation.rowid_variable = col_id\n",
    "\n",
    "documentation.sample_dict = {\n",
    "    \"HOOT\": hoot_mask,\n",
    "    \"Train\": train_mask,\n",
    "    \"Valid\": valid_mask,\n",
    "    \"Test\": test_mask,\n",
    "    \"OOT\": oot_mask,\n",
    "    \"Observable\": observable_mask,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor definition\n",
    "\n",
    "Categorical predictors have to be as type *category*, not *object*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.data_manipulation import split_predictors_bytype\n",
    "\n",
    "cols_pred, cols_pred_num, cols_pred_cat = split_predictors_bytype(data,\n",
    "                                                                  pred_list=cols_pred,\n",
    "                                                                  non_pred_list= [],\n",
    "                                                                  optimize_types=True,\n",
    "                                                                  convert_bool2int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical variable encoding\n",
    "\n",
    "## Dummy encoding\n",
    "\n",
    "**By default**, the categorical variables are processed as dummies (i.e. each value of categorical variable is treated as a separate binary variable) in LightGBM. Unlike xgboost, LightGBM is able to do this by itself (if the type of the variable is properly set as `category`), so **no further steps from the user are needed**.\n",
    "\n",
    "There are some categorical variables (e.g. variable with many distinct value, variable with ordinal business meaning, variable where the default rate can be mapped to its continous characteristic etc.) where it is better to encode such variable as a numeric one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean target encoding\n",
    "\n",
    "The basic type of encoding is mean target encoding. Each value of the variable is encoded as weighted average of the average default rate of observations having this particular value and the overall average default rate. More precisely, $MTE_C$ (mean target encoded value of category *C*) can be calculated as\n",
    "\n",
    "$$\n",
    "MTE_C = \\frac{\\sum_{i \\in C}{w_i y_i} + \\rho \\sum_{j \\in \\{1,\\ldots,n\\}}{w_j y_j}}\n",
    "             {\\sum_{i \\in C}{w_i} + \\rho \\sum_{j \\in \\{1,\\ldots,n\\}}{w_j}}\n",
    "$$\n",
    "\n",
    "where $y$ denotes target, $w$ denotes observation weight and $\\rho$ is a **regularization parameter**. By changing this regularization parameter, you can change, how close will the *MTE* values be to the overall average. It is important to notice that this parameter is the same for small and large categories which result in small categories being relatively closer to the overall average than large categories. This should help you to deal with **outliers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.variable_encoding import MeanTargetEncoder\n",
    "\n",
    "mte = MeanTargetEncoder(\n",
    "    regularization_parameter = 0.05,\n",
    "    unknown_fill_value = 'mean',\n",
    ")\n",
    "cols_pred_mte = []\n",
    "\n",
    "for predictor in cols_pred_cat:\n",
    "    mte.fit(predictor=data[train_mask][predictor],\n",
    "            target=data[train_mask][col_target],\n",
    "            weight=data[train_mask][col_weight])\n",
    "    data[predictor+'_MTE'] = mte.transform(data[predictor])\n",
    "    cols_pred_mte.append(predictor+'_MTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cols_pred_mte].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other options to encode the categorical variables:\n",
    "- **Grouping and WOE transformation** - the same way as we use for logistic regression. This might be useful if you want to group multiple categories into one in some logical way - use interactive grouping from standard PSW for this. Like Mean target encoding, WOE values also have the target encoded inside them, which is quite a pleasant property of them.\n",
    "- **Ordinal transformation** - for variables that have specific business meaning that can be translated into order. For example, you can encode *EDUCATION* as `1 - elementary`, `2 - secondary`, `3 - bachelor`, `4 - postgrad` etc. This must be done manually based on your business knowledge.\n",
    "- **Use metric instead of dimension** - you can also use something similar to mean target encoding but with mean value of some metric (property) of that category. E.g. for variable *REGION*, you can encode each of its catagories as mean income in the region. This must be done manually based on you business knowledge.\n",
    "\n",
    "*Example of manual encoding:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dict = {'AAA': 6000,\n",
    "                 'BBB': 2500,\n",
    "                 'CCC': 2650,\n",
    "                 'DDD': 1200,\n",
    "                 'EEE': 9000,\n",
    "                 'FFF': 1000,\n",
    "                 'GGG': 5000,\n",
    "                 np.nan: 0,\n",
    "                }\n",
    "\n",
    "data['Categorical_4_ENC'] = data['Categorical_4'].replace(encoding_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature preselection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment of numerical variables for the analyses\n",
    "\n",
    "During the workflow we will need to work with numerical predictors as with categorical several times (namely PSI calculation and stability charts). For these reasons, we create fake binning: we bin each numerical predictor equifrequently to `bin_count` bins, keep the categorical predictors as they are and then crate fake \"WOE\" for them using `Grouping` class well known from traditional Python Scoring Workflow.\n",
    "\n",
    "This is just a trick to enable the parts of the workflow that expect certain categorizations of the predictors. It should not be considered a proper \"WOE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_count = 4\n",
    "\n",
    "from scoring.features import fake_binning\n",
    "from scoring.grouping import Grouping, NumpyJSONEncoder\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "bin_dict = fake_binning(data[train_mask][cols_pred], bin_count = bin_count)\n",
    "\n",
    "with open('fake_binning.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(bin_dict, file, ensure_ascii=False, cls=NumpyJSONEncoder, indent=2)\n",
    "\n",
    "stability_grouping = Grouping(\n",
    "    columns = [column for column in data[cols_pred] if is_numeric_dtype(data[column])],\n",
    "    cat_columns = [column for column in data[cols_pred] if not is_numeric_dtype(data[column])],\n",
    ")\n",
    "stability_grouping.load('fake_binning.json')\n",
    "data_bins = stability_grouping.transform(data[cols_pred])\n",
    "bin_columns_to_replace = list()\n",
    "for column in data_bins.columns:\n",
    "    if column in data:\n",
    "        bin_columns_to_replace.append(column)\n",
    "        print(\"Column\", column, \"dropped as it already existed in the data set.\")\n",
    "data = data.drop(bin_columns_to_replace, axis=\"columns\")\n",
    "data = data.join(data_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_value = 0\n",
    "\n",
    "cols_pred_num_wo_nan = []\n",
    "for column in cols_pred_num:\n",
    "    if data[column].isnull().sum() > 0:\n",
    "        new_name = column + '_WONAN'\n",
    "        data[new_name] = data[column].fillna(fillna_value)\n",
    "        cols_pred_num_wo_nan.append(new_name)\n",
    "        print(f'Column {new_name} created where NaN values were filled by {fillna_value}.')\n",
    "    else:\n",
    "        cols_pred_num_wo_nan.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population stability index\n",
    "\n",
    "**Population Stability Index (PSI)** is calculated for each predictor. This index quantifies how stable is distribution of the values of the predictor in time. More about PSI here: http://ucanalytics.com/blogs/population-stability-index-psi-banking-case-study/\n",
    "\n",
    "For numerical predictors we use the fake grouping from the previous step, i.e. each numerical predictor is categorized into `bin_count` quantiles (and separate category for missings if applicable). Categorical predictors are kept as they are.\n",
    "\n",
    "The function `psi_calc_df()` which we use takes data frame and list of predictors and calculates for each predictor average weighted PSI from all two consecutive months weighted PSIs (e.g. let's have months 1, 2, 3, weighted PSIs are calculated for combinations (1,2), (2,3) and average of these values is returned).\n",
    "\n",
    "It is important to notice that if for certain month a certain category is missing, this category is not taken into account by the PSI calculation.\n",
    "\n",
    "It is reasonable to use only such predictors which have a \"reasonable\" PSI (i.e. PSI under certain threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.stability_index import psi_calc_df\n",
    "\n",
    "cols_pred_num_dis = [col_name + '_WOE' for col_name in cols_pred_num]\n",
    "\n",
    "monthly_psi, masked_psi = psi_calc_df(data, cols_pred_psi=cols_pred_num_dis+cols_pred_cat, col_month=\"MONTH\")\n",
    "display(monthly_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_threshold = 0.25\n",
    "\n",
    "print(f'Variables with PSI < {psi_threshold}:')\n",
    "cols_selected_psi = [\n",
    "    column[:-4] if column[-4:]=='_WOE'\n",
    "    else column for column in list(monthly_psi[monthly_psi['PSI avg per month'] < psi_threshold]['Variable'])\n",
    "]\n",
    "print(cols_selected_psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical variable clustering\n",
    "\n",
    "- Starts with each variable as a separate cluster\n",
    "- Creates clusters based on highest average correlations\n",
    "- The stopping criterion is either parameter `max_cluster_correlation` - once no correlation between clusters is larger than this parameter, the clustering is finished; or `max_clusters` - when this many clusters are created, the clustering is finished. If both specified, the one that makes less clusters is used.\n",
    "At the end we take only one representant (the most powerful one) from each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import variable_clustering\n",
    "\n",
    "clustering_correlation = variable_clustering.CorrVarClus(\n",
    "    max_correlation=0.75,\n",
    "    # max_clusters=9,\n",
    "    standardize=True,\n",
    "    sample_size=50000,\n",
    ")\n",
    "\n",
    "clustering_correlation.fit(data[train_mask][cols_pred_num_wo_nan+cols_pred_mte], data[train_mask][col_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_correlation.draw()\n",
    "clustering_correlation.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best variables based on correlation clustering:\")\n",
    "cols_selected_corr = [\n",
    "    column[:-6] if column[-6:]=='_WONAN' else\n",
    "    column[:-4] if column[-4:]=='_MTE' else\n",
    "    column for column in clustering_correlation.bestVariables()]\n",
    "print(cols_selected_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting\n",
    "\n",
    "This workflow contains set of methods (functions) that are necessary to develop and fine-tune gradient boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred_num = [column for column in cols_pred_num if (column in cols_selected_psi) and (column in cols_selected_corr)]\n",
    "cols_pred_cat = [column for column in cols_pred_cat if (column in cols_selected_psi) and (column in cols_selected_corr)]\n",
    "cols_pred_mte = [column + '_MTE' for column in cols_pred_cat]\n",
    "\n",
    "cols_pred_boosting = cols_pred_num + cols_pred_cat\n",
    "# cols_pred_boosting = cols_pred_num + cols_pred_mte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotone constraints\n",
    "\n",
    "Business meaning of certain variables (typically mean target encoded or WOE encoded, but also other variables where it makes sense) might imply that the dependence of the target on those variables is monotonic. Gradient boosting algorithms allow us to enforce the monotonity condition for these variables, so the splits in the trees inside the gradient boosting are done in such way that the monotonity is not broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotone_constraints_dict = {predictor: 0 for predictor in cols_pred_boosting}\n",
    "monotone_constraints_dict['AGE'] = -1\n",
    "monotone_constraints_dict['Numerical_1'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monotone_constraints_str = '('\n",
    "# for predictor in cols_pred_boosting:\n",
    "#     monotone_constraints_str += monotone_constraints_dict[predictor].astype(int).astype(str)+','\n",
    "# monotone_constraints_str = monotone_constraints_str[:-1]+')'\n",
    "# print(monotone_constraints_str)\n",
    "\n",
    "monotone_constraints_tup = tuple(monotone_constraints_dict[predictor] for predictor in cols_pred_boosting)\n",
    "print(monotone_constraints_tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "        'learning_rate':0.05,\n",
    "        'num_leaves':100,\n",
    "        'colsample_bytree':0.75,\n",
    "        'subsample':0.75,\n",
    "        'subsample_freq':1,\n",
    "        'max_depth':3,\n",
    "        'min_split_gain':0.0,\n",
    "        'max_delta_step':0.0,\n",
    "        'max_bin':20,\n",
    "        'metric':'auc',\n",
    "        'objective':'binary',\n",
    "        'early_stopping_rounds':100,\n",
    "        'num_boost_round':100000,\n",
    "        'seed':1234,\n",
    "        'monotone_constraints':monotone_constraints_tup,\n",
    "        'verbose':1,\n",
    "        'n_jobs':6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = default_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tunning \n",
    "Method `param_hyperopt()` is based on maximalization of 3-fold cross-validation AUC.  \n",
    "Output is a dictionary of optimalized hyperparameters that could be paste into params before method iniciations.\n",
    "\n",
    "There is an optional parameter `space` where you can insert your own space of possible hyperparameters to be searched. If this parameter is kept as `None`, a default space is used (see the source code if you want to review the default space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "from importlib import reload\n",
    "from scoring import lgbm \n",
    "lgbm=reload(lgbm)\n",
    "\n",
    "model_lgb = lgbm.LGBM_model(cols_pred_boosting,\n",
    "                            params,\n",
    "                            use_CV=False,\n",
    "                            CV_folds=3,\n",
    "                            CV_seed=9876)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = model_lgb.param_hyperopt(\n",
    "        data[train_mask],\n",
    "        data[valid_mask],\n",
    "        data[train_mask][col_target],\n",
    "        data[valid_mask][col_target],\n",
    "        n_iter = 2,\n",
    "        space = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = default_params\n",
    "\n",
    "for par in best_params:\n",
    "    params[par] = best_params[par]\n",
    "    \n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.params = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "First we compute SHAP values of each variables (more about them later in this notebook), the we add varible to model one by one (from highest absolute SHAP to the least) and observe how the predictive power of the model is changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_shap = model_lgb.print_shap_values(cols_pred_num, cols_pred_cat, data[train_mask], data[valid_mask], data[train_mask][col_target], data[valid_mask][col_target],data[test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.feature_selection import get_shap_feature_importance, boost_feature_selection, plot_feature_selection\n",
    "\n",
    "fe_params = params.copy()\n",
    "if 'monotone_constraints' in fe_params: del fe_params['monotone_constraints']\n",
    "if 'num_boost_round' in fe_params: del fe_params['num_boost_round']\n",
    "if 'early_stopping_rounds' in fe_params: del fe_params['early_stopping_rounds']\n",
    "\n",
    "fi_columns = get_shap_feature_importance(\n",
    "    names_columns = cols_pred_boosting,\n",
    "    shap_values = model_lgb.shap_values,\n",
    ")\n",
    "\n",
    "boost_aucs = boost_feature_selection(\n",
    "    params = fe_params,\n",
    "    df = data,\n",
    "    col_target = col_target,\n",
    "    base_columns = [],\n",
    "    fi_columns = fi_columns,\n",
    "    train_mask = train_mask, \n",
    "    test_mask = valid_mask,\n",
    "    n_seed = 3, \n",
    "    n_fold = 5,\n",
    "    step = 1,\n",
    "    boost = 'lgb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_selection(fi_columns, boost_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = pd.DataFrame([[c[0], a] for c, a in zip(fi_columns, boost_aucs['test-auc-mean'])])\n",
    "auc_df.columns=['Feature','Test-AUC']\n",
    "maximizing = auc_df['Test-AUC'].argmax()+1\n",
    "\n",
    "print('Columns selected by selection algorithm:')\n",
    "cols_selected_auc = list(auc_df.iloc[:maximizing]['Feature'])\n",
    "print(cols_selected_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred_num = [column for column in cols_pred_num if (column in cols_selected_auc)]\n",
    "cols_pred_cat = [column for column in cols_pred_cat if (column in cols_selected_auc)]\n",
    "# cols_pred_mte = [column for column in cols_pred_mte if (column in cols_selected_auc)]\n",
    "\n",
    "cols_pred_boosting_final = cols_pred_num + cols_pred_cat\n",
    "# cols_pred_boosting_final = cols_pred_num + cols_pred_mte\n",
    "\n",
    "monotone_constraints_tup_final = tuple(monotone_constraints_dict[predictor] for predictor in cols_pred_boosting_final)\n",
    "params['monotone_constraints'] = monotone_constraints_tup_final\n",
    "\n",
    "model_lgb.params = params\n",
    "model_lgb.cols_pred = cols_pred_boosting_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: List of lgbm boosters (models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model_lgb.fit_model(\n",
    "    data[train_mask],\n",
    "    data[valid_mask],\n",
    "    data[train_mask][col_target],\n",
    "    data[valid_mask][col_target]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.show_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "In case of CV is chosen, then the predictions are average predictions from each of CV models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = model_lgb.predict(model1, data[test_mask])\n",
    "print(2 * roc_auc_score(data[test_mask][col_target], predictions) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable gain\n",
    "\n",
    "Loss of a single decision tree $T$ is defined as $L(T) = \\sum_{i=1}^{n_T}{L_j}$ where $L_i$ are losses in leaves of tree $T$. When a new split is made (and leave $i$ is split into two new leafs $i1$ and $i2$), the loss of tree $T$ changes by $Gain_i = -L_i + L_{i1} + L_{i2}$ - this is gain of the new split.\n",
    "\n",
    "Gain of a variable $V$ in a gradient boosting model is sum of loss function gain caused by splits in inidividual decision tree that use that particular variable, i.e. $Gain(V) = \\sum_{\\forall T} \\sum_{\\forall i:i\\,\\mathrm{uses}\\,V} Gain_i$.\n",
    "\n",
    "Output: DataFrame with features and chosen importance\n",
    "\n",
    "In case of CV is chosen, then the variable importance is computed as the average variable importance from each CV models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp=model_lgb.plot_imp(model1, 'importance_gain', ret=True, show= True, n_predictors=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP values\n",
    "\n",
    "### Shap values for each variable\n",
    "\n",
    "Shapley values show impact of each variable to the prediction. Computationaly efficient library SHAP is used to calculate them for us.\n",
    "\n",
    "In the first SHAP chart below, each row shows impact of a single variable. There are many dots in each row and each of the dots represents a single observation. On the x-axis, there is impact on model output. As baseline for each observation we take prediction where the variable is replaced by its expected value. When the variable is added to the model, the **prediction for each observation changes. This change is showed as the position of the dot on the x-axis**. The value of the variable itself is color-coded (the scale is separately calibrated for each variable). The \"thickness\" of the dot clusters in the charts shows how many observations have that specific value.\n",
    "\n",
    "On the second chart, each variable is represented by a bar. This bar is average of absolute values of the SHAP values from the first chart. This shows how important is each variable by telling us how impactful on the final prediction the variable is.\n",
    "\n",
    "More theoretical background for Shapley values can be found here https://christophm.github.io/interpretable-ml-book/shapley.html\n",
    "\n",
    "Output: DataFrame with features and its mean absolute shap values that coresponds with second chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp_shap = model_lgb.print_shap_values(cols_pred_num, cols_pred_cat, data[train_mask], data[valid_mask], data[train_mask][col_target], data[valid_mask][col_target],data[test_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap interaction matrix\n",
    "\n",
    "Prints shap interaction matrix, based on https://christophm.github.io/interpretable-ml-book/shap.html#shap-interaction-value.\n",
    "It prints sum of absolute interactions values throught all observations.\n",
    "Diagonal values are manually set to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.print_shap_interaction_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap dependence plot\n",
    "Note: If y (second feature) is not specified, it is found automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.shap_dependence_plot(x='Numerical_1',y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.shap_dependence_plot(x='Numerical_1',y='Categorical_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap force plot for one observation\n",
    "If you are cuious why was given decision to particular observation.  \n",
    "Note: values in upper chart are in logloss, values in lower chart are in probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.shap_one_row(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal contribution\n",
    "All features are one by one removed from model training and performance on the test data is computed.  \n",
    "Output is dataframe with 4 columns - feature, gini with feature, gini without feature and difference of gini with feature and gini without feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = model_lgb.marginal_contribution(\n",
    "        data[train_mask],\n",
    "        data[valid_mask],\n",
    "        data[train_mask][col_target],\n",
    "        data[valid_mask][col_target],\n",
    "        data[test_mask],\n",
    "        data[test_mask][col_target]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependency Plots and Accumulated Local Effects plot\n",
    "\n",
    "**PDP (Partial Dependency Plots)** are showing overall trend of the model output (prediction) related to one particular predictor. We calculate PDP's for each predictor's values.\n",
    "\n",
    "First, we group the predictor values into several bins (corresponding to the splits inside the decision trees). Then for each observation (more precisely, for a reasonably sized random subsample) calculate the model output in **hypothetical situation when the predictor would change its value to be in the particular bin** and all the other varibles' values would remain the same. Average of these values over all observations for each particular bin is *mean Partial Dependency value*. When these values are plotted with the bins on x-axis, the PDP plot is formed. This plot shows how the mean of the prediction changes when the variable changes (and all other variables remain the same).\n",
    "\n",
    "We don't calculate just *mean Partial Dependency* but also its quantiles and median.\n",
    "\n",
    "PDP makes sense also for categorical variables as we can easily calculate these values also for each particular category of a categorical variable.\n",
    "\n",
    "More about PDP: https://christophm.github.io/interpretable-ml-book/pdp.html\n",
    "\n",
    "**ALE (Accumuated Local Effects)** are very similar to PDP, however for each bin we don't caluclate the average prediction, but average difference of predictions if we move from one bin to the next one. The we accumulate these differences which forms the ALE plot.\n",
    "\n",
    "This plot does not make sense for unordered categorical features, so it is missing in charts for categorical features.\n",
    "\n",
    "More about ALE: https://christophm.github.io/interpretable-ml-book/ale.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation.model = (model1[0],'LGBM',model1[0].feature_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.doctools import PartialDependencePlotCalculator\n",
    "\n",
    "pdp = PartialDependencePlotCalculator(documentation)\n",
    "\n",
    "for pred in model1[0].feature_name():\n",
    "    print(pred)\n",
    "    pdp_pred = pdp.s([(data[test_mask],'test')]).p([pred]).calculate()\n",
    "    pdp_pred.get_visualization(output_folder=output_folder+'/pdp')\n",
    "    display(pdp_pred.get_table())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Conditional Expectation plots\n",
    "\n",
    "**Individual Conditional Expectations** are actually \"dismantled\" PDP's. For each observation, we show how the prediction would change if one particular variable was chagning its values (and all the other variables remained the same) and we draw these lines all into one chart (in our case there are lines for 250 randomly chosen observations). There is also mean PDP showed by a thick line in the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.doctools import IceplotRuCalculator\n",
    "\n",
    "ice = IceplotRuCalculator(documentation)\n",
    "\n",
    "for pred in model1[0].feature_name():\n",
    "    print(pred)\n",
    "    ice_pred = ice.s([(data[test_mask],'test')]).p([pred]).calculate()\n",
    "    ice_pred.get_visualization(output_folder=output_folder+'/ice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability charts\n",
    "\n",
    "The stability chart show the following for each predictor:\n",
    "- share of each category (using the fake Grouping from the beginning of the workflow) in time\n",
    "- bad rate of each category in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_bins = [col+'_WOE' for col in model1[0].feature_name()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_bins:\n",
    "    documentation.GroupedEvaluation(\n",
    "        data,\n",
    "        predictor=col,\n",
    "        sample=\"Observable\",\n",
    "        target=col_target,\n",
    "        weight=col_weight,\n",
    "        grouping=stability_grouping,\n",
    "        show_gini=False, # must be False if fake grouping without real WOEs is used\n",
    "        output_folder=output_folder + \"/stability\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSI charts\n",
    "\n",
    "These charts compare distribution of values of the predictor in data (parameter `data`) in each month (identified by `col_month`) with distribution on a reference set (by default we set `data[train_mask]`).\n",
    "\n",
    "Categorical predictors are left as they are, numerical are automatically binned to deciles (or user defined `q` quantiles).\n",
    "\n",
    "The stability is quantified separately for each month and drawn into a chart. The quantifiers of stability are:\n",
    "\n",
    "- **PSI (Population Stability Index)**: http://ucanalytics.com/blogs/population-stability-index-psi-banking-case-study/\n",
    "- **Bhattacharyya distance**: https://en.wikipedia.org/wiki/Bhattacharyya_distance\n",
    "- **Jensen-Shannon distance**: https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.PSI import psi_in_time\n",
    "\n",
    "for pred in model1[0].feature_name():\n",
    "    psi_table = psi_in_time(\n",
    "        data = data,\n",
    "        data_expected = data[train_mask],\n",
    "        pred = pred,\n",
    "        col_month = col_month,\n",
    "        q = 10,\n",
    "        output_folder = output_folder +'/psi'\n",
    "    )\n",
    "    display(psi_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_score = 'SCORE_LGB'\n",
    "\n",
    "data[col_score] = model_lgb.predict(model1, data)\n",
    "\n",
    "if col_score not in documentation.scores:\n",
    "    documentation.scores.append(col_score)\n",
    "\n",
    "print(\"Column\", col_score, \"with the prediction added/modified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create equivalent XGBoost model\n",
    "\n",
    "Training XGBoost model using the same parameters we used for LightGBM.\n",
    "\n",
    "Only applicable to numerical data. If there are any categorical variables in the dataset, they must be converted to numerical or dummy variables by the user first.\n",
    "\n",
    "If you want to have the XGBoost as the final output of this workflow we strongly recommend to start with the converted variables from the beginning and also use all the metrics from *Interpretation* chapter on the XGBoost model to interpret the model that you'll be actually deploying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = params\n",
    "\n",
    "cols_pred_xgb = cols_pred_num\n",
    "xgb_monotone_constraints = str(tuple(\n",
    "    [params['monotone_constraints'][n] for n, col in enumerate(cols_pred) if col in cols_pred_xgb]\n",
    "))\n",
    "\n",
    "xgb_early_stopping_rounds = params_lgbm['early_stopping_rounds']\n",
    "xgb_num_boost_round = params_lgbm['num_boost_round']\n",
    "\n",
    "params_xgb = {\n",
    "    'n_estimators': params_lgbm['num_boost_round'],\n",
    "    'learning_rate': params_lgbm['learning_rate'], \n",
    "    'max_depth' : params_lgbm['max_depth'],\n",
    "    'min_child_weight' : params_lgbm['min_child_weight'], \n",
    "    'max_delta_step' : params_lgbm['max_delta_step'],\n",
    "    'gamma' : params_lgbm['min_split_gain'],\n",
    "    'reg_alpha' : params_lgbm['reg_alpha'], \n",
    "    'reg_lambda' : params_lgbm['reg_lambda'], \n",
    "    'subsample' : params_lgbm['subsample'],   \n",
    "    'colsample_bytree' : params_lgbm['colsample_bytree'],      \n",
    "    'seed' : params_lgbm['seed'],\n",
    "    'scale_pos_weight' : 1,\n",
    "    'tree_method' : 'hist',\n",
    "    'grow_policy' : 'lossguide',\n",
    "    'silent' : True,\n",
    "    'booster' : 'gbtree',\n",
    "    'n_jobs' : params_lgbm['n_jobs'],\n",
    "    'monotone_constraints' : xgb_monotone_constraints,\n",
    "}\n",
    "\n",
    "if params_lgbm['objective'] == 'binary':\n",
    "    params_xgb['objective'] = 'binary:logistic'\n",
    "    if params_lgbm['metric'] == 'auc':\n",
    "        params_xgb['eval_metric'] = 'auc'\n",
    "    else: \n",
    "        params_xgb['eval_metric'] = 'logloss'\n",
    "\n",
    "\n",
    "if params_lgbm['objective'] == 'regression':\n",
    "    params_xgb['objective'] = 'reg:squarederror'\n",
    "    params_xgb['metric'] = 'rmse'\n",
    "\n",
    "if params_lgbm['objective'] == 'multiclass':\n",
    "    params_xgb['objective'] == 'multi:softprob'\n",
    "    params_xgb['metric']  = 'mlogloss'\n",
    "    params_xgb['num_class'] = params_lgbm['num_class']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbooster = xgb.train(params = params_xgb,\n",
    "                      dtrain = xgb.DMatrix(data[train_mask][cols_pred_xgb],data[train_mask][col_target]),\n",
    "                      evals = ((xgb.DMatrix(data[train_mask][cols_pred_xgb], data[train_mask][col_target]), 'train'),\n",
    "                               (xgb.DMatrix(data[valid_mask][cols_pred_xgb], data[valid_mask][col_target]), 'test'),\n",
    "                              ),\n",
    "                      num_boost_round = xgb_num_boost_round,\n",
    "                      early_stopping_rounds = xgb_early_stopping_rounds,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsonrep = model1[0].dump_model()\n",
    "\n",
    "with open('model.json', 'w') as outfile:\n",
    "    json.dump(jsonrep, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model1[0], open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1[0].save_model('model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export from XGBoost\n",
    "\n",
    "To be able to implement the model in Blaze advisor, we need to develop model in XGBoost as we currently can use only native XGBoost format in the Blaze tools. Refer to chapter *Create equivalent XGBoost model* above to create such model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooster.dump_model('modelX.json', dump_format='json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbooster, open(\"modelX.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native TXT (for Blaze tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbooster.dump_model('modelX.txt', dump_format='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.boosting import xgb2sql    \n",
    "xgb2sql('modelX.txt', 'modelX.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Blaze code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.boosting import xgb2blz    \n",
    "xgb2blz('modelX.txt', 'modelXblz.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data to PSW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the power of the model, import the data to the *Performance characteristics* of the PSW. In this part we prepare the data and metadata to be loaded inside the PSW.\n",
    "\n",
    "The time, day, month, target, base, weight and score coumns will be exported in the data. If there are some other columns that need to be analyzed inside PSW, please add them to the list `other_columns_to_be_kept`. This might typically be old score, short target and its base etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns_to_be_kept = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"col_score\"] = col_score\n",
    "\n",
    "json.dump(metadata, open(\"metadata_gb_wfl.json\", \"w\", encoding=\"utf8\"), indent=4)\n",
    "\n",
    "default_columns_to_be_kept = [col_time, col_month, col_day, col_target, col_base, col_weight, col_reject, col_datatype, col_id, col_score]\n",
    "\n",
    "data[default_columns_to_be_kept + other_columns_to_be_kept].to_csv('data_from_gb_wfl.csv')\n",
    "\n",
    "pickle.dump(documentation, open(\"documentation_gb_wfl.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
