{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:28pt;font-weight:bold\">Home Credit Python Scoring for Collections </font> <br><br>\n",
    "<span style=\"font-size:28pt;font-weight:bold\">    Model Evaluation and Comparison Workflow v.0.8.1</font>\n",
    "\n",
    "**Copyright:**\n",
    "\n",
    "© 2017-2020, Pavel Sůva, Marek Teller, Martin Kotek, Jan Zeller, Marek Mukenšnabl, Kirill Odintsov, Jan Hynek, Elena Kuchina, Lubor Pacák, Naďa Horká and Home Credit & Finance Bank Limited Liability Company, Moscow, Russia – all rights reserved\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the [License](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "For list of contributors see [Gitlab page](https://git.homecredit.net/risk/python-scoring-workflow) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:18.737902Z",
     "start_time": "2020-11-06T08:24:11.011299Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "import operator\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# check your tqdm version if import fails\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "import scoring\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# import category_encoders as ce\n",
    "# import graphviz\n",
    "# import json\n",
    "# import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:18.762834Z",
     "start_time": "2020-11-06T08:24:18.739895Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.close_figures=True\n",
    "from IPython.display import display, Markdown, HTML\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30\n",
    "output_folder = 'documentation_evaluation_demo'\n",
    "\n",
    "if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "if not os.path.exists(output_folder+'/performance'): os.makedirs(output_folder+'/performance')\n",
    "if not os.path.exists(output_folder+'/daily_bootstrap'): os.makedirs(output_folder+'/daily_bootstrap')\n",
    "scoring.check_version('0.9.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation, the dataset with all the out of time data for both workflows is needed to upload. E.g. you can upload the transformation z dataset.\n",
    "\n",
    "For High and Low, the respective scoring models have to be uploaded as well, to be able to score the Low dataset with High model and vice versa. \n",
    "It is also possible to import new dataset and score by all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:21.426854Z",
     "start_time": "2020-11-06T08:24:18.764828Z"
    }
   },
   "outputs": [],
   "source": [
    "from scoring import db\n",
    "\n",
    "data = db.read_csv(\n",
    "    r\"coll_demo_data\\dataset_scored_z_demo.csv\",\n",
    "    sep=\",\",\n",
    "    decimal=\".\",\n",
    "    optimize_types=True,\n",
    "    encoding=\"utf-8\",\n",
    "#     index_col=\"ID\",\n",
    "    low_memory=False,\n",
    "    keep_default_na=False,\n",
    "    na_values=[\"\"],\n",
    ")\n",
    "print(\"Data loaded on\", datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Main Banking Product if it is not part of the loaded dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:21.438826Z",
     "start_time": "2020-11-06T08:24:21.428813Z"
    }
   },
   "outputs": [],
   "source": [
    "### THESE COLUMNS MUST BE INCLUDED IN THE DATA SET ###\n",
    "# name of your target column in your dataset\n",
    "col_target_orig = \"TARGET_10D\"\n",
    "col_target = 'TARGET_Z'\n",
    "\n",
    "# name of the time column in your dataset\n",
    "col_time = \"STARTDATE\"\n",
    "# name of the workflow column - usually Low, High, Medium etc.\n",
    "col_workflow = 'PROCESS_NAME'\n",
    "col_treatment = 'HIGHER_TREATMENT'\n",
    "# name of the product column - e.g. CASH/CONSUMER\n",
    "col_product = 'TYPEOCREDIT'\n",
    "\n",
    "\n",
    "### THESE COLUMNS DON'T HAVE TO BE INCLUDED IN THE DATA SET AND ARE CREATED AUTOMATICALLY LATER with this given name ###\n",
    "#name of the base column\n",
    "col_base = \"BASE\"\n",
    "# name of the year column\n",
    "col_year = \"YEAR\"\n",
    "# name of the month column\n",
    "col_month = \"MONTH\"\n",
    "# name of the day column\n",
    "col_day = \"DAY\"\n",
    "# name of the year and week column\n",
    "col_week = \"WEEK\"\n",
    "\n",
    "\n",
    "col_instalment = 'AMTINSTALMENT'\n",
    "col_receivable = 'AMT_RECEIVABLE' \n",
    "\n",
    "\n",
    "# #name of the weight column \n",
    "col_weight = 'WEIGHT'\n",
    "\n",
    "col_score = 'SCORE'\n",
    "col_workflow_high = 'HIGHER_TREATMENT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same masks as were created in the Python Scoring Workflow step, for identifying Train, Valid, Test and OOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:21.453786Z",
     "start_time": "2020-11-06T08:24:21.440782Z"
    }
   },
   "outputs": [],
   "source": [
    "train_mask = (data[\"data_type\"] == \"train\") & (data[col_base] == 1)\n",
    "valid_mask = (data[\"data_type\"] == \"valid\") & (data[col_base] == 1)\n",
    "test_mask = (data[\"data_type\"] == \"test\") & (data[col_base] == 1)\n",
    "oot_mask = (data[\"data_type\"] == \"oot\") & (data[col_base] == 1)\n",
    "hoot_mask = (data[\"data_type\"] == \"hoot\") & (data[col_base] == 1)\n",
    "observable_mask = data[col_base] == 1\n",
    "\n",
    "# for upload of new, Out-of-Time dataset for evaluation: \n",
    "# oot_mask = data[col_base] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datetime Format Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:21.458735Z",
     "start_time": "2020-11-06T08:24:21.454744Z"
    }
   },
   "outputs": [],
   "source": [
    "dtime_input_format = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:39.440375Z",
     "start_time": "2020-11-06T08:24:21.460728Z"
    }
   },
   "outputs": [],
   "source": [
    "col_day = 'day'\n",
    "data[[col_time,'PAIDDATE']] = data[[col_time,'PAIDDATE']].apply(pd.to_datetime, format=dtime_input_format, cache=False)\n",
    "# data[col_time] = pd.to_datetime(data[col_time], format=dtime_input_format, cache=False)\n",
    "data[col_time] = data[col_time].apply(lambda x: pd.to_datetime(str(x), format='%Y-%m-%d'))\n",
    "data['day'] = data[col_time].apply(lambda x: x.to_pydatetime().date().timetuple().tm_yday)  #<--day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Final Models and their Grouping to Score the Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we created two distinct models for High and Low treatments in the Python Scoring Workflow, we have to upload and score the whole dataset for the contracts which were in the other treatment. That means, score Low treatment contracts by High model and vice versa. \n",
    "We will do it on our Z_score dataset. \n",
    "Please be aware that if you created any feature-engineering or interactions predictors for any of the models, you have to include the same for the dataset with both treatments, too.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:39.491748Z",
     "start_time": "2020-11-06T08:24:39.442361Z"
    }
   },
   "outputs": [],
   "source": [
    "from scoring.data_manipulation import split_predictors_bytype\n",
    "\n",
    "cols_pred = list(pd.read_csv(r'coll_demo_data/predictors.csv', sep = ',', decimal = '.', \n",
    "                   encoding = 'windows-1251', low_memory = False, header = None)[0])\n",
    "\n",
    "cols_pred, cols_pred_num, cols_pred_cat = split_predictors_bytype(data,\n",
    "                                                                  pred_list=cols_pred,\n",
    "                                                                  non_pred_list= [],\n",
    "                                                                  optimize_types=True,\n",
    "                                                                  convert_bool2int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:39.569571Z",
     "start_time": "2020-11-06T08:24:39.493743Z"
    }
   },
   "outputs": [],
   "source": [
    "num_to_cat = ['SHOPPER', 'CODEREGIONCLIENT']\n",
    "cat_to_num = []\n",
    "to_delete_category = ['AMTBALANCEACTUALCONTRACT', 'AMTINCOMEHOUSEHOLD']\n",
    "    \n",
    "print('Initial number of numerical predictors:',len(cols_pred_num))\n",
    "print('Initial number of categorical predictors:',len(cols_pred_cat))\n",
    "\n",
    "for i in num_to_cat:\n",
    "    if i in cols_pred_num:\n",
    "        cols_pred_num.remove(i)\n",
    "        cols_pred_cat.append(i)\n",
    "        if data[i].dtypes not in {'object', 'string', 'category'}:\n",
    "            try:\n",
    "                data[i] = data[i].astype('category')\n",
    "                print('Predictor ' + str(i)  + ' was moved to categorical predictors.')\n",
    "            except:\n",
    "                data[i] = data[i].astype(str)\n",
    "    else:\n",
    "        print('Predictor '+ str(i) + ' not in numerical predictors.')\n",
    "\n",
    "for i in cat_to_num:\n",
    "    if i in cols_pred_num:\n",
    "        cols_pred_cat.remove(i)\n",
    "        cols_pred_num.append(i)\n",
    "        if not pd.api.types.is_numeric_dtype(data[i].values.dtypes):\n",
    "            try:\n",
    "                data[i].astype(np.number)\n",
    "                data[i] = data[i].astype(get_optimal_numerical_type(i))\n",
    "                print('Predictor' + str(i)  + ' was moved to numerical predictors.')\n",
    "            except:\n",
    "                print('Column {0} couldn\\'t be converted to numerical. Will be used as categorical.'.format(name))\n",
    "                cols_pred_num.remove(i)\n",
    "                cols_pred_cat.append(i)\n",
    "       \n",
    "    else:\n",
    "        print('Predictor '+ str(i) + ' not in numerical predictors.')\n",
    "\n",
    "if len(num_to_cat + cat_to_num) > 0:\n",
    "    print('Category for some predictors has changed.')  \n",
    "\n",
    "\n",
    "for i in to_delete_category:\n",
    "    if i in cols_pred_num:\n",
    "        cols_pred_num.remove(i)\n",
    "        print('Predictor ' + str(i) + ' was deleted from numerical predictors.')\n",
    "    elif i in cols_pred_cat:\n",
    "        cols_pred_cat.remove(i)\n",
    "        print('Predictor ' + str(i) + ' was deleted from categorical predictors.')\n",
    "    else:\n",
    "        print('Predictor ' + str(i) + ' was not found in predictors.')\n",
    "    \n",
    "print('Updated number of numerical predictors:',len(cols_pred_num))\n",
    "print('Updated number of categorical predictors:',len(cols_pred_cat))\n",
    "cols_pred = cols_pred_num + cols_pred_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the Dataset by Transformed Target Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation is based on the comparison of results for multiple models. In this workflow, we can directly use \n",
    "\n",
    "- Transformed Target Model (one-model approach, logistic regression)\n",
    "- Two-model Approach (distinct models for Higher and Lower workflow)\n",
    "- LGBM/XGBoost model on Transformed Target\n",
    "- Sorting by Receivable\n",
    "- Random model as a baseline\n",
    "\n",
    "It is possible and viable to comment out all the models which you do not need. The easiest way is by Ctrl+/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:39.971396Z",
     "start_time": "2020-11-06T08:24:39.570536Z"
    }
   },
   "outputs": [],
   "source": [
    "from scoring.grouping import Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:39.976344Z",
     "start_time": "2020-11-06T08:24:39.972354Z"
    }
   },
   "outputs": [],
   "source": [
    "grouping_trans = r\"coll_demo_data/mg_demo_z.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:39.984353Z",
     "start_time": "2020-11-06T08:24:39.977341Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "grouping_z = Grouping(columns = sorted(cols_pred_num),\n",
    "                    cat_columns = sorted(cols_pred_cat),\n",
    "                    group_count=5, \n",
    "                    min_samples=100, \n",
    "                    min_samples_cat=100) \n",
    "grouping_z.load(grouping_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.086362Z",
     "start_time": "2020-11-06T08:24:39.986318Z"
    }
   },
   "outputs": [],
   "source": [
    "data_woe = grouping_z.transform(data, columns_to_transform=grouping_z.bins_data_.keys(), transform_to=\"woe\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.186671Z",
     "start_time": "2020-11-06T08:24:41.087359Z"
    }
   },
   "outputs": [],
   "source": [
    "woe_columns_to_replace = list()\n",
    "for column in data_woe.columns:\n",
    "    if column in data:\n",
    "        woe_columns_to_replace.append(column)\n",
    "        print(\"Column\", column, \"dropped as it already existed in the data set.\")\n",
    "data = data.drop(woe_columns_to_replace, axis=\"columns\")\n",
    "data = data.join(data_woe)\n",
    "\n",
    "del data_woe\n",
    "gc.collect()\n",
    "\n",
    "print(\"Added WOE variables. Number of columns:\", data.shape[1])\n",
    "cols_woe = [s + \"_WOE\" for s in cols_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the Model Filename for Z-transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.201631Z",
     "start_time": "2020-11-06T08:24:41.187668Z"
    }
   },
   "outputs": [],
   "source": [
    "model_filename_z = r'coll_demo_data/myModelSW_demo_Z.model'\n",
    "\n",
    "modelSW_Z = pickle.load(open(model_filename_z, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.247508Z",
     "start_time": "2020-11-06T08:24:41.202628Z"
    }
   },
   "outputs": [],
   "source": [
    "data['SCORE'] = modelSW_Z.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.257482Z",
     "start_time": "2020-11-06T08:24:41.249503Z"
    }
   },
   "outputs": [],
   "source": [
    "data['UPLIFT_1MODEL'] = 2*data['SCORE']-1\n",
    "\n",
    "col_score = 'UPLIFT_1MODEL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCORE BY LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.262468Z",
     "start_time": "2020-11-06T08:24:41.259476Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_filename_lgbm = 'lgbm_final_model_20200611.model'\n",
    "\n",
    "# modelSW_LGBM = pickle.load(open(model_filename_lgbm, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.267455Z",
     "start_time": "2020-11-06T08:24:41.264462Z"
    }
   },
   "outputs": [],
   "source": [
    "# data['SCORE_LGBM'] = modelSW_LGBM.predict(data[cols_pred], num_iteration = modelSW_LGBM.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.272441Z",
     "start_time": "2020-11-06T08:24:41.268452Z"
    }
   },
   "outputs": [],
   "source": [
    "# data['UPLIFT_LGBM_MODEL'] = 2*data['SCORE_LGBM']-1\n",
    "\n",
    "# lgbm_score  = 'UPLIFT_LGBM_MODEL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the Dataset by HIGH Treatment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the Grouping for High Treatment Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.277428Z",
     "start_time": "2020-11-06T08:24:41.273439Z"
    }
   },
   "outputs": [],
   "source": [
    "grouping_high = r'coll_demo_data/mg_demo_high.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.285407Z",
     "start_time": "2020-11-06T08:24:41.279423Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "grouping_h = Grouping(columns = sorted(cols_pred_num),\n",
    "                    cat_columns = sorted(cols_pred_cat),\n",
    "                    group_count=5, \n",
    "                    min_samples=100, \n",
    "                    min_samples_cat=100) \n",
    "grouping_h.load(grouping_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:41.911701Z",
     "start_time": "2020-11-06T08:24:41.289395Z"
    }
   },
   "outputs": [],
   "source": [
    "data_woe = grouping_h.transform(data, columns_to_transform=grouping_h.bins_data_.keys(), transform_to=\"woe\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.019447Z",
     "start_time": "2020-11-06T08:24:41.914696Z"
    }
   },
   "outputs": [],
   "source": [
    "woe_columns_to_replace = list()\n",
    "for column in data_woe.columns:\n",
    "    if column in data:\n",
    "        woe_columns_to_replace.append(column)\n",
    "        print(\"Column\", column, \"dropped as it already existed in the data set.\")\n",
    "data = data.drop(woe_columns_to_replace, axis=\"columns\")\n",
    "data = data.join(data_woe)\n",
    "\n",
    "del data_woe\n",
    "gc.collect()\n",
    "\n",
    "print(\"Added WOE variables. Number of columns:\", data.shape[1])\n",
    "cols_woe = [s + \"_WOE\" for s in cols_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the Model Filename for HIGH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.027392Z",
     "start_time": "2020-11-06T08:24:42.020410Z"
    }
   },
   "outputs": [],
   "source": [
    "model_filename_high = r'coll_demo_data\\myModelSW_demo_HIGH.model'\n",
    "\n",
    "modelSW_HIGH = pickle.load(open(model_filename_high, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.097203Z",
     "start_time": "2020-11-06T08:24:42.028388Z"
    }
   },
   "outputs": [],
   "source": [
    "high_score = 'SCORE_HIGH'\n",
    "data[high_score] = modelSW_HIGH.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the Dataset by Low Treatment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the Grouping Filename for LOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.102191Z",
     "start_time": "2020-11-06T08:24:42.098202Z"
    }
   },
   "outputs": [],
   "source": [
    "grouping_low = r'coll_demo_data/mg_demo_low.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the Model Filename for LOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.110850Z",
     "start_time": "2020-11-06T08:24:42.103187Z"
    }
   },
   "outputs": [],
   "source": [
    "model_filename_low = r'coll_demo_data/myModelSW_demo_LOW.model'\n",
    "modelSW_LOW = pickle.load(open(model_filename_low, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.118828Z",
     "start_time": "2020-11-06T08:24:42.111847Z"
    }
   },
   "outputs": [],
   "source": [
    "grouping_l = Grouping(columns = sorted(cols_pred_num),\n",
    "                    cat_columns = sorted(cols_pred_cat),\n",
    "                    group_count=5, \n",
    "                    min_samples=100, \n",
    "                    min_samples_cat=100) \n",
    "grouping_l.load(grouping_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.536666Z",
     "start_time": "2020-11-06T08:24:42.120824Z"
    }
   },
   "outputs": [],
   "source": [
    "data_woe = grouping_l.transform(data, columns_to_transform=grouping_l.bins_data_.keys(), transform_to=\"woe\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.647216Z",
     "start_time": "2020-11-06T08:24:42.538696Z"
    }
   },
   "outputs": [],
   "source": [
    "woe_columns_to_replace = list()\n",
    "for column in data_woe.columns:\n",
    "    if column in data:\n",
    "        woe_columns_to_replace.append(column)\n",
    "        print(\"Column\", column, \"dropped as it already existed in the data set.\")\n",
    "data = data.drop(woe_columns_to_replace, axis=\"columns\")\n",
    "data = data.join(data_woe)\n",
    "\n",
    "del data_woe\n",
    "gc.collect()\n",
    "\n",
    "print(\"Added WOE variables. Number of columns:\", data.shape[1])\n",
    "cols_woe = [s + \"_WOE\" for s in cols_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.710438Z",
     "start_time": "2020-11-06T08:24:42.648213Z"
    }
   },
   "outputs": [],
   "source": [
    "low_score = 'SCORE_LOW'\n",
    "data[low_score] = modelSW_LOW.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profit Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Score Difference for Profit Optimizaton\n",
    "\n",
    "We are using here slightly different score_difference as usual. \n",
    "For the uplift (gain), we need\n",
    "<center>Uplift = Probability of Repaid in High - Probability of Repaid in Low</center>\n",
    "\n",
    "This can be achieved also as Probability of Unpaid in High - Probability of Unpaid in Low, as we are modelling the unpaid target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:42.717388Z",
     "start_time": "2020-11-06T08:24:42.712402Z"
    }
   },
   "outputs": [],
   "source": [
    "col_score_diff = 'SCORE_DIFF' \n",
    "data[col_score_diff] = data['SCORE_LOW'] - data['SCORE_HIGH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Random Segmentation as a Challenger\n",
    "\n",
    "Creates for each valid row a random number between -1 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.093835Z",
     "start_time": "2020-11-06T08:24:42.719381Z"
    }
   },
   "outputs": [],
   "source": [
    "# random uplift\n",
    "col_uplift_random = 'UPLIFT_RANDOM'\n",
    "data[col_uplift_random] = data[col_base].apply( lambda x: np.random.uniform(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the names of the ASB columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.260389Z",
     "start_time": "2020-11-06T08:24:43.094833Z"
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "col_ASB = 'ASB_REAL'\n",
    "col_ASB_diff_one = 'ASB_DIFF_TRANSFORMED'\n",
    "col_ASB_diff_two = 'ASB_DIFF_TWOMODEL'\n",
    "col_ASB_diff_rnd = 'ASB_DIFF_RANDOM'\n",
    "col_ASB_diff_rec = 'ASB_DIFF_RECEIVABLE'\n",
    "# col_ASB_diff_lgbm = 'ASB_DIFF_LGBM'\n",
    "\n",
    "col_cost = 'WF_COST'\n",
    "col_CAASB_OPT = 'WORKFLOW_CAASB_optimum'\n",
    "\n",
    "col_CAASB = 'CAASB_REAL'\n",
    "col_CAASB_diff_one = 'CAASB_DIFF_TRANS'\n",
    "col_CAASB_diff_two = 'CAASB_DIFF_TWOMODEL'\n",
    "col_CAASB_diff_rnd = 'CAASB_DIFF_RANDOM'\n",
    "col_CAASB_diff_rec = 'CAASB_DIFF_RECEIVABLE'\n",
    "# col_CAASB_diff_lgbm = 'CAASB_DIFF_LGBM'\n",
    "\n",
    "# set the names of the instalment and receivable columns \n",
    "col_instalment = 'AMTINSTALMENT'\n",
    "col_receivable = 'AMT_RECEIVABLE'\n",
    "\n",
    "# creating new columns, the optimal way\n",
    "data.loc[:,col_ASB] = 0\n",
    "data.loc[:,col_CAASB] = 0\n",
    "data.loc[:,col_CAASB_OPT] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.272356Z",
     "start_time": "2020-11-06T08:24:43.261386Z"
    }
   },
   "outputs": [],
   "source": [
    "col_product = 'MBP'\n",
    "display(data[col_product].unique())\n",
    "products_all = data[col_product].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.295296Z",
     "start_time": "2020-11-06T08:24:43.273354Z"
    }
   },
   "outputs": [],
   "source": [
    "# RENAME the columns to the provision coefficients which you will use, your products will be created automatically \n",
    "# TODO: How to do it in general?? \n",
    "\n",
    "\n",
    "provision_coeffs = pd.DataFrame(columns=['C_0', 'C_1'], index=products_all)\n",
    "provision_coeffs.rename_axis('Banking Products', axis='rows', inplace=True)\n",
    "provision_coeffs.rename_axis('Coefficients', axis='columns', inplace=True)\n",
    "\n",
    "# Set the right ratio of provision coefficients for the CAASB computing, for all products: \n",
    "\n",
    "# Set the correct coefficients' values \n",
    "\n",
    "# for KZ, I've used the exponential trend from provisions 2020/01\n",
    "\n",
    "provision_coeffs['C_0']['PoS'] = 0.04 \n",
    "provision_coeffs['C_0']['Cash Walk-in'] = 0.05 \n",
    "provision_coeffs['C_0']['Cash X-sell'] = 0.024 \n",
    "provision_coeffs['C_0']['RC'] = 0.05\n",
    "\n",
    "provision_coeffs['C_1']['PoS'] = 0.13\n",
    "provision_coeffs['C_1']['Cash Walk-in'] = 0.22\n",
    "provision_coeffs['C_1']['Cash X-sell'] = 0.10 \n",
    "provision_coeffs['C_1']['RC'] = 0.10 # different computation\n",
    "\n",
    "\n",
    "\n",
    "print('TABLE of Provision Coefficients')\n",
    "display(provision_coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.305269Z",
     "start_time": "2020-11-06T08:24:43.297291Z"
    }
   },
   "outputs": [],
   "source": [
    "# COSTS for each workflow used in the model - first creating a dictionary:\n",
    "workflows = data[col_workflow].unique()\n",
    "costs_workflow = {name:0 for name in workflows}\n",
    "\n",
    "costs_workflow[workflows[0]] = 20\n",
    "costs_workflow[workflows[1]] = 50\n",
    "\n",
    "display(costs_workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.316492Z",
     "start_time": "2020-11-06T08:24:43.306266Z"
    }
   },
   "outputs": [],
   "source": [
    "data[col_cost] = data[col_workflow].apply(\n",
    "    lambda x: costs_workflow[workflows[0]] if x == workflows[0] \n",
    "    else costs_workflow[workflows[1]] )\n",
    "\n",
    "# the column can get created as 'Category' instead of 'Number'\n",
    "# therefore we simply retype it to optimal numerical type \n",
    "\n",
    "data[col_cost] = data[col_cost].astype(np.number)\n",
    "# data[col_cost] = data[col_cost].astype(get_optimal_numerical_type(data[col_cost]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAASB Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Computing CAASB (The Cost Adjusted Average Saved Balance):\n",
    "$$CAASB = ASB - costs$$\n",
    "$$ASB = c_i \\cdot R - \\sum_{u=0}^{m} P_u \\cdot c_u \\cdot(R - (m-u) r)$$\n",
    "- $R$ receivable on contract at the beginning of collection phase\n",
    "- $r$ instalment amount\n",
    "- $c_u$ provision coefficient, $u$-th bucket\n",
    "- $P_u$ probability estimation of collection process results to $u$-th bucket\n",
    "- $m$ end bucket\n",
    "\n",
    "For computing CAASB, we need to know the receivable and amount of instalment, provision coefficients and costs. \n",
    "Set the name of new columns and assign receivable and instalment amount to specific column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Early ASB and CAASB \n",
    "**Warning:** This equation is one of the possible CAASB equations, which is computed at DPD = 1 with target date still in bucket 1.  \n",
    "\n",
    "$$ASB = c_0 \\cdot R - \\sum_{u=0}^{1} P_u \\cdot c_u \\cdot(R - (1-u) \\cdot r)$$\n",
    "\n",
    "For different workflows, the equation can differ. <br>\n",
    "**Before computing ASB, you should always check and eventually change the equations for Precollection or later stages according to the general equation above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.332449Z",
     "start_time": "2020-11-06T08:24:43.317489Z"
    }
   },
   "outputs": [],
   "source": [
    "# COMPUTATION OF PRECO ASB  -definitions\n",
    "\n",
    "def get_asb_coefficient_p0(instalment, product, c_0, c_1):\n",
    "    asb_coef_p0 = (c_0[product.values]).astype(np.number)*instalment.values # c_0 * r \n",
    "    return asb_coef_p0\n",
    "\n",
    "def get_asb_coefficient_p1(receivable, instalment, product, c_0, c_1):\n",
    "    # (c_0 - c_1)*R\n",
    "    asb_coef_p1 = (c_0[product.values] - c_1[product.values]).astype(np.number)*receivable.values\n",
    "    return asb_coef_p1\n",
    "\n",
    "def get_asb_real(asb_coef_p0, asb_coef_p1, target):\n",
    "    asb_real = target*asb_coef_p1.values + (1-target)*asb_coef_p0.values\n",
    "    return asb_real\n",
    "\n",
    "def get_asb_diff(asb_coef_p0, asb_coef_p1, score_diff):\n",
    "    asb_diff = - score_diff*asb_coef_p1.values + score_diff*asb_coef_p0.values\n",
    "    return asb_diff\n",
    "    \n",
    "def get_caasb_real(asb_real, costs_real):\n",
    "    caasb_real = asb_real.values - costs_real.values\n",
    "    return caasb_real\n",
    "\n",
    "def get_caasb_diff(asb_diff, costs_all):\n",
    "    caasb_diff = asb_diff.values - costs_all['HIGH'] + costs_all['LOW']\n",
    "    return caasb_diff    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing CAASBs for all the versions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:43.784742Z",
     "start_time": "2020-11-06T08:24:43.333446Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "asb_coef_p0 = get_asb_coefficient_p0(\n",
    "    data[col_instalment], \n",
    "    data[col_product], \n",
    "    provision_coeffs['C_0'],\n",
    "    provision_coeffs['C_1'])\n",
    "\n",
    "asb_coef_p1 = get_asb_coefficient_p1(\n",
    "    data[col_receivable], \n",
    "    data[col_instalment], \n",
    "    data[col_product], \n",
    "    provision_coeffs['C_0'], \n",
    "    provision_coeffs['C_1'])\n",
    "\n",
    "# real ASB and ASB differences\n",
    "# commented out the models which we do not have\n",
    "\n",
    "data[col_ASB] = get_asb_real(asb_coef_p0, asb_coef_p1, data[col_target_orig])\n",
    "data[col_ASB_diff_one] = get_asb_diff(asb_coef_p0, asb_coef_p1, data[col_score])\n",
    "data[col_ASB_diff_two] = get_asb_diff(asb_coef_p0, asb_coef_p1, data[col_score_diff])\n",
    "data[col_ASB_diff_rnd] = get_asb_diff(asb_coef_p0, asb_coef_p1, data[col_uplift_random])\n",
    "# data[col_ASB_diff_lgbm] = get_asb_diff(asb_coef_p0, asb_coef_p1, data[lgbm_score])\n",
    "\n",
    "# real CAASB and CAASB differences\n",
    "\n",
    "data[col_CAASB] = get_caasb_real(data[col_ASB], data[col_cost])\n",
    "data[col_CAASB_diff_one] = get_caasb_diff(data[col_ASB_diff_one], costs_workflow)\n",
    "data[col_CAASB_diff_two] = get_caasb_diff(data[col_ASB_diff_two], costs_workflow)\n",
    "data[col_CAASB_diff_rnd] = get_caasb_diff(data[col_ASB_diff_rnd], costs_workflow)\n",
    "# data[col_CAASB_diff_lgbm] = get_caasb_diff(data[col_ASB_diff_lgbm], costs_workflow)\n",
    "\n",
    " # Adding sorting by Receivable\n",
    "data[col_CAASB_diff_rec] = data[col_receivable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the dataset with all scores and computed CAASB-diffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:59.073291Z",
     "start_time": "2020-11-06T08:24:43.785739Z"
    }
   },
   "outputs": [],
   "source": [
    "savepath = os.path.join(output_folder,'dataset_demo_out_caasb.csv')\n",
    "data.to_csv(savepath, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAASB Impact Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset with CAASB Computed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:59.079276Z",
     "start_time": "2020-11-06T08:24:59.074287Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = os.path.join(output_folder,'dataset_demo_out_caasb.csv')\n",
    "# data = db.read_csv(\n",
    "#     path,\n",
    "#     sep=\",\",\n",
    "#     decimal=\".\",\n",
    "#     optimize_types=True,\n",
    "#     encoding=\"utf-8\",\n",
    "# #     index_col=\"ID\",\n",
    "#     low_memory=False,\n",
    "#     keep_default_na=False,\n",
    "#     na_values=[\"\"],\n",
    "# )\n",
    "# print(\"Data loaded on\", datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set which models will be shown in the Impact Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:24:59.084298Z",
     "start_time": "2020-11-06T08:24:59.080272Z"
    }
   },
   "outputs": [],
   "source": [
    "# order of contracts by the money (CAASB) impact\n",
    "_uplift_metrics = [col_CAASB_diff_one, \n",
    "                   col_CAASB_diff_two, \n",
    "                   col_CAASB_diff_rnd, \n",
    "                   col_CAASB_diff_rec, \n",
    "#                    col_CAASB_diff_lgbm\n",
    "                  ]\n",
    "\n",
    "# variant with the ordering by uplift/score_difference\n",
    "_uplift_metrics_score = [col_score, \n",
    "#                         lgbm_score,\n",
    "                        col_score_diff,\n",
    "                        col_receivable,\n",
    "                        col_uplift_random]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the uplift metrics based on: \n",
    "\n",
    "https://tech.wayfair.com/data-science/2018/10/pylift-a-fast-python-package-for-uplift-modeling/\n",
    "\n",
    "https://pylift.readthedocs.io/en/latest/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:41:20.525288Z",
     "start_time": "2020-11-06T08:41:20.504346Z"
    }
   },
   "outputs": [],
   "source": [
    "from scoring import coll_evaluation\n",
    "\n",
    "impact_analysis = coll_evaluation.CollModelImpactAnalysis(data[oot_mask], \n",
    "                                                          weight=col_weight,\n",
    "                                                          base = col_base,\n",
    "                                                          uplift_metrics=_uplift_metrics, \n",
    "                                                          treatment=col_treatment, \n",
    "                                                          outcome=col_target_orig, \n",
    "                                                          target=col_target, \n",
    "                                                          caasb=col_CAASB, \n",
    "                                                          time=col_time,\n",
    "                                                          n_bins=10, \n",
    "                                                          n_bootstraps = 2,\n",
    "                                                          n_histories=20,\n",
    "                                                          use_caasb=True,\n",
    "                                                          alpha=2,\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:41:23.066524Z",
     "start_time": "2020-11-06T08:41:21.809503Z"
    }
   },
   "outputs": [],
   "source": [
    "Bootstrapped_CAASB_curves = impact_analysis.bootstrap_impact_analysis(by_day=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:41:23.477722Z",
     "start_time": "2020-11-06T08:41:23.068483Z"
    }
   },
   "outputs": [],
   "source": [
    "impact_analysis.plot_impact_analysis(Bootstrapped_CAASB_curves,\n",
    "#                                     savefile=os.path.join(output_folder,\"avg_CAASB_predicted_demo.png\")\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Optimal Capacity Constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This part simulates the daily segmentation with two possible settings:**\n",
    "\n",
    "- the cutoff for High workflow is fixed on some level between 0 and 100 %\n",
    "- the cutoff is dynamically decided each day for getting the best outcome possible \n",
    "\n",
    "For the day-by-day strategy, the ideal cutoff can be different from the overall cutoff displayed in the Impact Analysis Chapter. Therefore, here you have the possibility to decide by everyday results, what is the best performing cutoff. \n",
    "\n",
    "It is possible and recommended to first run the simulations with dynamic cutoff and then after choosing the best performing, to run it again with a fixed cutoff to obtain the money saving results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Challengers, each set in the dictionary is one strategy \n",
    "- by using multiple challengers choosing the best (winner) for the day out of the list\n",
    "    - this is good for finding the 'most often winning model', even though we are then using just one model in business setting\n",
    "- by using one model as a strategy at a time - list has only one member\n",
    "\n",
    "The \\_type is just a name for the strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:41:26.964469Z",
     "start_time": "2020-11-06T08:41:26.957523Z"
    }
   },
   "outputs": [],
   "source": [
    "challengers = {}\n",
    "\n",
    "challengers[0] = {'challengers' : ['CAASB_DIFF_TRANS'], '_type' : 'CAASB_DIFF_TRANS' }\n",
    "challengers[1] = {'challengers' : ['CAASB_DIFF_TWOMODEL'], '_type' : 'CAASB_DIFF_TWOMODEL' }\n",
    "# challengers[2] = {'challengers' : ['CAASB_DIFF_LGBM'], '_type' : 'CAASB_DIFF_LGBM' }\n",
    "challengers[2] = {'challengers' : ['CAASB_DIFF_RANDOM'], '_type' : 'CAASB_DIFF_RANDOM' }\n",
    "challengers[3] = {'challengers' : ['CAASB_DIFF_RECEIVABLE'], '_type' : 'CAASB_DIFF_RECEIVABLE' }\n",
    "\n",
    "challengers[4]=  {'challengers' : ['CAASB_DIFF_TRANS',\n",
    "                                   'CAASB_DIFF_TWOMODEL', \n",
    "                                   'CAASB_DIFF_RANDOM', \n",
    "#                                    'CAASB_DIFF_LGBM',  \n",
    "                                   'CAASB_DIFF_RECEIVABLE'],\\\n",
    "                                   '_type' : 'all'}\n",
    "\n",
    "\n",
    "# challengers[5]=  {'challengers' : ['CAASB_DIFF_TRANS', 'CAASB_DIFF_TWOMODEL', 'CAASB_DIFF_RECEIVABLE'],\\\n",
    "#                   '_type' : 'three_models'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the Impact Analysis**\n",
    "\n",
    "For getting the overall impact analysis (bootstrapped or not), and for computing the historical daily distributions (again bootstrapped or not), we need to set following attributes:\n",
    "\n",
    "- the dataset on which we want to get the impact (usually out of time dataset of its subset)\n",
    "- weight - the name of weight column (if we use weights which is highly recommended)\n",
    "- base - the name of the base column (usually col_base or equivalent)\n",
    "- uplift_metrics - a list of all modelled scores/CAASBs which we want to consider in the impact analysis, based on which we want to sort. \n",
    "- treatment, outcome, target, time, caasb - the names of the respective columnns in the dataset\n",
    "- n_bins - how many bins (how fine) we want to see for the distribution. The result is always n_bins+1. E.g.: n_bins=10 will result into 11 bins by 10 percentage points (0 %, 10 %, 20 %, ... 90 %, 100 %)\n",
    "- n_bootstraps - on how many bootstraps we will compute the results, for creating intervals\n",
    "- n_histories - how many histories are computed in the simulation - for computing the intervals then\n",
    "- use_caasb - if True it will compute average CAASB as an outcome (y-axis), if False, the outcome (1=no payment, 0=payment) will be used\n",
    "\n",
    "The outcome is a basis for computing the random trajectories for cumulative impact of the strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:07.110577Z",
     "start_time": "2020-11-06T08:52:20.848911Z"
    }
   },
   "outputs": [],
   "source": [
    "HISTORICAL_DAILY_WINNER_DISTRIBUTION = impact_analysis.get_hist_daily_winner_distribution(42, challengers, \n",
    "                                                                                          dynamic_cutoff=True, \n",
    "                                                                                          fixed_cutoff=0.2,\n",
    "                                                                                          progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:10.099026Z",
     "start_time": "2020-11-06T08:53:10.079225Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the results \n",
    "savepath = os.path.join(output_folder,'dataset_hist_daily_winner_demo.csv')\n",
    "HISTORICAL_DAILY_WINNER_DISTRIBUTION.to_csv(savepath, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:14.115602Z",
     "start_time": "2020-11-06T08:53:14.111587Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the results \n",
    "\n",
    "# path = os.path.join(output_folder,'dataset_hist_daily_winner_demo.csv')\n",
    "# HISTORICAL_DAILY_WINNER_DISTRIBUTION = db.read_csv(\n",
    "#     path,\n",
    "#     sep=\",\",\n",
    "#     decimal=\".\",\n",
    "#     optimize_types=True,\n",
    "#     encoding=\"utf-8\",\n",
    "# #     index_col=\"ID\",\n",
    "#     low_memory=False,\n",
    "#     keep_default_na=False,\n",
    "#     na_values=[\"\"],\n",
    "# )\n",
    "# print(\"Data loaded on\", datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Cumulative Impact for Champion/Challenger Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'trajectories' from randomly chosen bootstraps for each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:29.452632Z",
     "start_time": "2020-11-06T08:53:14.115703Z"
    }
   },
   "outputs": [],
   "source": [
    "collection_winner_histories = impact_analysis.create_trajectories(HISTORICAL_DAILY_WINNER_DISTRIBUTION, \n",
    "                                                 _seed=33, \n",
    "                                                 challengers=challengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose your Challenger and Champion strategy**\n",
    "\n",
    "In order to be able to directly compare, we need to choose just two strategies. The one which we compare to the 'base' is Challenger, the base to which challenger is compared is Champion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:29.457618Z",
     "start_time": "2020-11-06T08:53:29.453596Z"
    }
   },
   "outputs": [],
   "source": [
    "choices = []\n",
    "for key in challengers.keys():\n",
    "    choices.append(challengers[key]['_type'])\n",
    "\n",
    "print (choices)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:29.464074Z",
     "start_time": "2020-11-06T08:53:29.458584Z"
    }
   },
   "outputs": [],
   "source": [
    "challenger = choices[1] # challenger\n",
    "champion = choices[3] # champion \n",
    "print(f'challenger strategy: {challenger}')\n",
    "print(f'champion strategy: {champion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:30.238567Z",
     "start_time": "2020-11-06T08:53:29.465060Z"
    }
   },
   "outputs": [],
   "source": [
    "trajectories_deltas_differences = impact_analysis.get_deltas_difference(collection_winner_histories, \n",
    "                                                  challenger, \n",
    "                                                  champion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:31.290934Z",
     "start_time": "2020-11-06T08:53:30.239525Z"
    }
   },
   "outputs": [],
   "source": [
    "impact_analysis.plot_dynamic(trajectories_deltas_differences, challenger, champion, show='delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for winning model in a strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For having this plot functioning, you need to have a strategy in *challengers* with more than just one model (a list of models). Plot shows the ratio of winning approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:31.296879Z",
     "start_time": "2020-11-06T08:53:31.292900Z"
    }
   },
   "outputs": [],
   "source": [
    "all_models = collection_winner_histories[collection_winner_histories['type'] == 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:31.426711Z",
     "start_time": "2020-11-06T08:53:31.297877Z"
    }
   },
   "outputs": [],
   "source": [
    "impact_analysis.plot_winning(all_models, savefile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Cutoffs for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:31.451648Z",
     "start_time": "2020-11-06T08:53:31.427675Z"
    }
   },
   "outputs": [],
   "source": [
    "winners = pd.DataFrame()\n",
    "for metric in _uplift_metrics:\n",
    "    winners = winners.append(collection_winner_histories[collection_winner_histories['type'] == metric] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:31.628828Z",
     "start_time": "2020-11-06T08:53:31.452609Z"
    }
   },
   "outputs": [],
   "source": [
    "impact_analysis.plot_cutoffs(winners, savefile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Avg CAASB per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:31.814509Z",
     "start_time": "2020-11-06T08:53:31.629791Z"
    }
   },
   "outputs": [],
   "source": [
    "impact_analysis.plot_caasb(winners, savefile=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T08:53:32.032891Z",
     "start_time": "2020-11-06T08:53:31.815473Z"
    }
   },
   "outputs": [],
   "source": [
    "impact_analysis.plot_distribution_caasb(trajectories_deltas_differences, challenger, champion, show='absolute',\n",
    "                                       animation=False, savefile=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
